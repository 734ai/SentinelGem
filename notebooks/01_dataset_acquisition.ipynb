{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da94ffd6",
   "metadata": {},
   "source": [
    "# ðŸ“Š Dataset Acquisition for SentinelGem\n",
    "\n",
    "**Author:** Muzan Sano  \n",
    "**Purpose:** Download and prepare real cybersecurity datasets for SentinelGem training and testing\n",
    "\n",
    "This notebook identifies and downloads datasets that match our multimodal cybersecurity analysis requirements:\n",
    "\n",
    "### ðŸŽ¯ Target Dataset Categories\n",
    "- **ðŸ“§ Phishing Email Detection** - Real phishing samples vs legitimate emails\n",
    "- **ðŸ–¼ï¸ Screenshot/Image Phishing** - Fake websites, UI spoofing attempts\n",
    "- **ðŸŽ¤ Social Engineering Audio** - Voice-based attacks and scam calls\n",
    "- **ðŸ“‹ Malware Log Analysis** - System logs with malware activity\n",
    "- **ðŸ•µï¸ Network Traffic** - Suspicious network behavior patterns\n",
    "- **ðŸ” URL/Domain Analysis** - Malicious URLs and domain characteristics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"ðŸ›¡ï¸ SentinelGem Dataset Acquisition Started\")\n",
    "print(f\"ðŸ“… Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ðŸ“‚ Project Root: {project_root}\")\n",
    "print(f\"ðŸ Python Version: {sys.version}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26cfd71",
   "metadata": {},
   "source": [
    "## ðŸ” Kaggle Dataset Search\n",
    "\n",
    "Let's search for cybersecurity datasets on Kaggle that match our needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2bfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle search terms for cybersecurity datasets\n",
    "search_terms = [\n",
    "    \"phishing email detection\",\n",
    "    \"malware detection\",\n",
    "    \"network intrusion detection\", \n",
    "    \"social engineering\",\n",
    "    \"cybersecurity logs\",\n",
    "    \"phishing websites\",\n",
    "    \"spam detection\",\n",
    "    \"malicious urls\",\n",
    "    \"voice phishing\",\n",
    "    \"cyber threat detection\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ” Searching Kaggle for relevant cybersecurity datasets...\")\n",
    "print(f\"ðŸ“‹ Search terms: {', '.join(search_terms)}\")\n",
    "\n",
    "# We'll collect dataset information manually since Kaggle API requires authentication\n",
    "recommended_datasets = [\n",
    "    {\n",
    "        \"name\": \"phishing-site-urls\",\n",
    "        \"title\": \"Phishing Site URLs\", \n",
    "        \"url\": \"https://www.kaggle.com/datasets/taruntiwarihp/phishing-site-urls\",\n",
    "        \"description\": \"Collection of phishing and legitimate URLs for detection training\",\n",
    "        \"size\": \"~50MB\",\n",
    "        \"modality\": \"text/url\",\n",
    "        \"relevance\": \"high\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"malware-detection\", \n",
    "        \"title\": \"Malware Detection Dataset\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/xwolf12/malware-detection\",\n",
    "        \"description\": \"Malware samples and system behavior logs\",\n",
    "        \"size\": \"~200MB\",\n",
    "        \"modality\": \"logs/binary\",\n",
    "        \"relevance\": \"high\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"spam-email-detection\",\n",
    "        \"title\": \"Email Spam Detection Dataset\", \n",
    "        \"url\": \"https://www.kaggle.com/datasets/nitishabharathi/email-spam-dataset\",\n",
    "        \"description\": \"Email content for spam/phishing detection\",\n",
    "        \"size\": \"~25MB\",\n",
    "        \"modality\": \"text/email\",\n",
    "        \"relevance\": \"high\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"network-intrusion-detection\",\n",
    "        \"title\": \"Network Intrusion Detection\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection\", \n",
    "        \"description\": \"Network traffic patterns for intrusion detection\",\n",
    "        \"size\": \"~100MB\",\n",
    "        \"modality\": \"network/logs\",\n",
    "        \"relevance\": \"medium\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"android-malware-detection\",\n",
    "        \"title\": \"Android Malware Detection\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/shashwatwork/android-malware-detection-using-machine-learning\",\n",
    "        \"description\": \"Android app features for malware detection\", \n",
    "        \"size\": \"~15MB\",\n",
    "        \"modality\": \"features/mobile\",\n",
    "        \"relevance\": \"medium\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display dataset recommendations\n",
    "print(\"\\nðŸ“Š Recommended Datasets for SentinelGem:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, dataset in enumerate(recommended_datasets, 1):\n",
    "    print(f\"\\n{i}. **{dataset['title']}**\")\n",
    "    print(f\"   ðŸ”— URL: {dataset['url']}\")\n",
    "    print(f\"   ðŸ“ Description: {dataset['description']}\")\n",
    "    print(f\"   ðŸ“ Size: {dataset['size']}\")\n",
    "    print(f\"   ðŸŽ¯ Modality: {dataset['modality']}\")\n",
    "    print(f\"   â­ Relevance: {dataset['relevance']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d9092c",
   "metadata": {},
   "source": [
    "## ðŸŽµ Audio Dataset Search\n",
    "\n",
    "For social engineering voice detection, we need audio datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c93519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio datasets for social engineering detection\n",
    "audio_datasets = [\n",
    "    {\n",
    "        \"name\": \"common-voice\",\n",
    "        \"title\": \"Mozilla Common Voice\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/mozillaorg/common-voice\", \n",
    "        \"description\": \"Large-scale voice dataset - can be used to simulate social engineering scenarios\",\n",
    "        \"size\": \"~50GB (subset available)\",\n",
    "        \"modality\": \"audio/speech\",\n",
    "        \"use_case\": \"Voice pattern analysis, speech synthesis detection\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"speech-emotion-recognition\",\n",
    "        \"title\": \"Speech Emotion Recognition\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\",\n",
    "        \"description\": \"Emotional speech patterns - useful for detecting manipulative speech\",\n",
    "        \"size\": \"~200MB\", \n",
    "        \"modality\": \"audio/emotion\",\n",
    "        \"use_case\": \"Emotional manipulation detection in social engineering\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"voice-gender-detection\",\n",
    "        \"title\": \"Voice Gender Detection\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/primaryobjects/voicegender\",\n",
    "        \"description\": \"Voice characteristics dataset for pattern analysis\",\n",
    "        \"size\": \"~5MB\",\n",
    "        \"modality\": \"audio/features\", \n",
    "        \"use_case\": \"Voice spoofing and impersonation detection\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ðŸŽ¤ Audio Datasets for Social Engineering Detection:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, dataset in enumerate(audio_datasets, 1):\n",
    "    print(f\"\\n{i}. **{dataset['title']}**\")\n",
    "    print(f\"   ðŸ”— URL: {dataset['url']}\")\n",
    "    print(f\"   ðŸ“ Description: {dataset['description']}\")\n",
    "    print(f\"   ðŸ“ Size: {dataset['size']}\")\n",
    "    print(f\"   ðŸŽ¯ Use Case: {dataset['use_case']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4063505e",
   "metadata": {},
   "source": [
    "## ðŸ–¼ï¸ Image/Screenshot Datasets\n",
    "\n",
    "For phishing website and UI spoofing detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image datasets for phishing website detection\n",
    "image_datasets = [\n",
    "    {\n",
    "        \"name\": \"phishing-website-screenshots\",\n",
    "        \"title\": \"Phishing Website Screenshots\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/shashwatwork/phishing-website-screenshots\",\n",
    "        \"description\": \"Screenshots of phishing websites vs legitimate sites\",\n",
    "        \"size\": \"~500MB\",\n",
    "        \"modality\": \"image/screenshot\",\n",
    "        \"use_case\": \"Visual phishing detection, UI spoofing analysis\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"website-screenshots\",\n",
    "        \"title\": \"Website Screenshots Dataset\", \n",
    "        \"url\": \"https://www.kaggle.com/datasets/sid321axn/website-screenshots-dataset\",\n",
    "        \"description\": \"Large collection of website screenshots for classification\",\n",
    "        \"size\": \"~1GB\",\n",
    "        \"modality\": \"image/web\",\n",
    "        \"use_case\": \"Website legitimacy classification\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ui-mockups\",\n",
    "        \"title\": \"UI Design Screenshots\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/jonathanoheix/ui-design-screenshots\",\n",
    "        \"description\": \"Various UI designs - can help distinguish legitimate vs fake interfaces\",\n",
    "        \"size\": \"~300MB\",\n",
    "        \"modality\": \"image/ui\",\n",
    "        \"use_case\": \"UI authenticity verification\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ðŸ“· Image/Screenshot Datasets for Phishing Detection:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, dataset in enumerate(image_datasets, 1):\n",
    "    print(f\"\\n{i}. **{dataset['title']}**\")\n",
    "    print(f\"   ðŸ”— URL: {dataset['url']}\")\n",
    "    print(f\"   ðŸ“ Description: {dataset['description']}\")\n",
    "    print(f\"   ðŸ“ Size: {dataset['size']}\")\n",
    "    print(f\"   ðŸŽ¯ Use Case: {dataset['use_case']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a5a49",
   "metadata": {},
   "source": [
    "## ðŸ“‹ System Logs & Network Data\n",
    "\n",
    "For malware detection and system behavior analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log and network datasets\n",
    "log_datasets = [\n",
    "    {\n",
    "        \"name\": \"kdd-cup-99\",\n",
    "        \"title\": \"KDD Cup 1999 Network Intrusion Detection\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/galaxyh/kdd-cup-1999-data\",\n",
    "        \"description\": \"Classic network intrusion detection dataset\",\n",
    "        \"size\": \"~75MB\",\n",
    "        \"modality\": \"network/logs\",\n",
    "        \"use_case\": \"Network anomaly detection, intrusion patterns\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"windows-pe-malware-detection\",\n",
    "        \"title\": \"Windows PE Malware Detection\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/amauricio/pe-malware-machine-learning-dataset\",\n",
    "        \"description\": \"Windows PE file features for malware classification\",\n",
    "        \"size\": \"~100MB\",\n",
    "        \"modality\": \"binary/features\",\n",
    "        \"use_case\": \"Executable malware detection\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"system-call-traces\",\n",
    "        \"title\": \"System Call Traces for Malware Detection\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/selfishgene/syscall-sequences-malware-detection\", \n",
    "        \"description\": \"System call sequences from malware and benign processes\",\n",
    "        \"size\": \"~50MB\",\n",
    "        \"modality\": \"logs/syscall\",\n",
    "        \"use_case\": \"Behavioral malware detection\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"dns-tunneling-detection\",\n",
    "        \"title\": \"DNS Tunneling Detection\",\n",
    "        \"url\": \"https://www.kaggle.com/datasets/7h3rAm/dns-tunneling-queries\",\n",
    "        \"description\": \"DNS queries for detecting covert communication channels\",\n",
    "        \"size\": \"~25MB\",\n",
    "        \"modality\": \"network/dns\",\n",
    "        \"use_case\": \"Covert channel detection, C2 communication\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ðŸ“Š System Logs & Network Datasets:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, dataset in enumerate(log_datasets, 1):\n",
    "    print(f\"\\n{i}. **{dataset['title']}**\")\n",
    "    print(f\"   ðŸ”— URL: {dataset['url']}\")\n",
    "    print(f\"   ðŸ“ Description: {dataset['description']}\")\n",
    "    print(f\"   ðŸ“ Size: {dataset['size']}\")\n",
    "    print(f\"   ðŸŽ¯ Use Case: {dataset['use_case']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb3f52a",
   "metadata": {},
   "source": [
    "## ðŸš€ Dataset Download Commands\n",
    "\n",
    "Here are the Kaggle CLI commands to download the most relevant datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14388e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority datasets for immediate download\n",
    "priority_downloads = [\n",
    "    {\n",
    "        \"command\": \"kaggle datasets download -d taruntiwarihp/phishing-site-urls\",\n",
    "        \"description\": \"Phishing URLs - Critical for URL analysis\",\n",
    "        \"priority\": 1\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"kaggle datasets download -d nitishabharathi/email-spam-dataset\", \n",
    "        \"description\": \"Email spam/phishing - Critical for email analysis\",\n",
    "        \"priority\": 1\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"kaggle datasets download -d xwolf12/malware-detection\",\n",
    "        \"description\": \"Malware samples - Critical for threat detection\",\n",
    "        \"priority\": 1\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"kaggle datasets download -d shashwatwork/phishing-website-screenshots\",\n",
    "        \"description\": \"Phishing screenshots - Critical for visual detection\", \n",
    "        \"priority\": 2\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio\",\n",
    "        \"description\": \"Emotional speech - Important for social engineering\",\n",
    "        \"priority\": 2\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"kaggle datasets download -d galaxyh/kdd-cup-1999-data\",\n",
    "        \"description\": \"Network intrusion - Important for log analysis\",\n",
    "        \"priority\": 3\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ðŸŽ¯ Priority Dataset Downloads:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Group by priority\n",
    "for priority in [1, 2, 3]:\n",
    "    priority_items = [d for d in priority_downloads if d['priority'] == priority]\n",
    "    if priority_items:\n",
    "        print(f\"\\nðŸ”¥ Priority {priority} (Download First):\")\n",
    "        for item in priority_items:\n",
    "            print(f\"   ðŸ’» {item['command']}\")\n",
    "            print(f\"   ðŸ“ {item['description']}\")\n",
    "            print()\n",
    "\n",
    "print(\"\\nðŸ“‹ Download Instructions:\")\n",
    "print(\"1. Set up Kaggle API credentials: https://www.kaggle.com/docs/api\")\n",
    "print(\"2. Create kaggle.json with your API token\")\n",
    "print(\"3. Place in ~/.kaggle/ directory\")\n",
    "print(\"4. Run the download commands above\")\n",
    "print(\"5. Extract datasets to assets/datasets/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f41bb4",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Dataset Integration Strategy\n",
    "\n",
    "How we'll integrate these datasets into SentinelGem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration strategy for each modality\n",
    "integration_plan = {\n",
    "    \"text_phishing\": {\n",
    "        \"datasets\": [\"phishing-site-urls\", \"email-spam-dataset\"],\n",
    "        \"integration\": \"Train pattern recognition, improve Gemma 3n prompts\",\n",
    "        \"files\": [\"src/inference.py\", \"config/rules.yaml\"],\n",
    "        \"validation\": \"Test against existing phishing samples\"\n",
    "    },\n",
    "    \"image_analysis\": {\n",
    "        \"datasets\": [\"phishing-website-screenshots\", \"website-screenshots\"],\n",
    "        \"integration\": \"Enhance OCR pipeline with real phishing UI patterns\",\n",
    "        \"files\": [\"src/ocr_pipeline.py\"],\n",
    "        \"validation\": \"Visual similarity testing, pattern matching accuracy\"\n",
    "    },\n",
    "    \"audio_analysis\": {\n",
    "        \"datasets\": [\"ravdess-emotional-speech-audio\", \"voicegender\"],\n",
    "        \"integration\": \"Train social engineering voice pattern detection\",\n",
    "        \"files\": [\"src/audio_pipeline.py\"],\n",
    "        \"validation\": \"Emotion detection accuracy, speech pattern analysis\"\n",
    "    },\n",
    "    \"log_analysis\": {\n",
    "        \"datasets\": [\"kdd-cup-1999-data\", \"pe-malware-dataset\"],\n",
    "        \"integration\": \"Enhance malware detection rules and signatures\",\n",
    "        \"files\": [\"src/log_parser.py\", \"config/rules.yaml\"],\n",
    "        \"validation\": \"Intrusion detection accuracy, false positive rate\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ðŸ”§ Dataset Integration Strategy:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for modality, plan in integration_plan.items():\n",
    "    print(f\"\\nðŸŽ¯ **{modality.replace('_', ' ').title()}**\")\n",
    "    print(f\"   ðŸ“Š Datasets: {', '.join(plan['datasets'])}\")\n",
    "    print(f\"   ðŸ”§ Integration: {plan['integration']}\")\n",
    "    print(f\"   ðŸ“ Files: {', '.join(plan['files'])}\")\n",
    "    print(f\"   âœ… Validation: {plan['validation']}\")\n",
    "\n",
    "print(\"\\nðŸš€ Next Steps:\")\n",
    "print(\"1. Download priority datasets using Kaggle CLI\")\n",
    "print(\"2. Create data preprocessing notebooks\")\n",
    "print(\"3. Update threat detection rules with real patterns\")\n",
    "print(\"4. Retrain/fine-tune detection models\")\n",
    "print(\"5. Validate against known attack samples\")\n",
    "print(\"6. Update bootstrap notebook with real data examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152b640",
   "metadata": {},
   "source": [
    "## ðŸ“ Directory Structure for Datasets\n",
    "\n",
    "Let's create the recommended directory structure for organizing our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset directory structure\n",
    "dataset_structure = {\n",
    "    \"assets/datasets\": {\n",
    "        \"phishing\": [\"urls\", \"emails\", \"screenshots\"],\n",
    "        \"malware\": [\"samples\", \"logs\", \"network_traces\"],\n",
    "        \"audio\": [\"social_engineering\", \"emotional_speech\", \"voice_samples\"],\n",
    "        \"images\": [\"phishing_sites\", \"legitimate_sites\", \"ui_samples\"],\n",
    "        \"logs\": [\"system_logs\", \"network_logs\", \"application_logs\"],\n",
    "        \"processed\": [\"training\", \"validation\", \"testing\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "def create_directory_structure(base_path: Path, structure: dict):\n",
    "    \"\"\"Create directory structure recursively\"\"\"\n",
    "    for key, value in structure.items():\n",
    "        current_path = base_path / key\n",
    "        current_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"ðŸ“ Created: {current_path}\")\n",
    "        \n",
    "        if isinstance(value, dict):\n",
    "            create_directory_structure(current_path, value)\n",
    "        elif isinstance(value, list):\n",
    "            for subdir in value:\n",
    "                subdir_path = current_path / subdir\n",
    "                subdir_path.mkdir(parents=True, exist_ok=True)\n",
    "                print(f\"ðŸ“‚ Created: {subdir_path}\")\n",
    "\n",
    "# Create the directory structure\n",
    "print(\"ðŸ—ï¸ Creating Dataset Directory Structure:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "base_path = project_root\n",
    "create_directory_structure(base_path, dataset_structure)\n",
    "\n",
    "print(\"\\nâœ… Directory structure created successfully!\")\n",
    "print(\"\\nðŸ“‹ Directory Usage:\")\n",
    "print(\"- phishing/: Email, URL, and website phishing samples\")\n",
    "print(\"- malware/: Malware samples and behavioral logs\")\n",
    "print(\"- audio/: Voice recordings for social engineering detection\")\n",
    "print(\"- images/: Screenshots of websites and UI elements\")\n",
    "print(\"- logs/: System, network, and application log files\")\n",
    "print(\"- processed/: Cleaned and preprocessed data for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb5a5f4",
   "metadata": {},
   "source": [
    "## ðŸ”„ Data Processing Pipeline\n",
    "\n",
    "Once datasets are downloaded, here's how we'll process them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee746ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing pipeline template\n",
    "processing_pipeline = \"\"\"\n",
    "# SentinelGem Data Processing Pipeline\n",
    "# Run after downloading datasets\n",
    "\n",
    "# 1. Extract and organize downloaded datasets\n",
    "for dataset in assets/datasets/*/; do\n",
    "    echo \"Processing $dataset\"\n",
    "    unzip -q \"$dataset\"*.zip -d \"$dataset\" 2>/dev/null || true\n",
    "done\n",
    "\n",
    "# 2. Run data preprocessing notebooks\n",
    "jupyter nbconvert --execute notebooks/02_data_preprocessing.ipynb\n",
    "jupyter nbconvert --execute notebooks/03_feature_extraction.ipynb\n",
    "\n",
    "# 3. Update threat detection rules\n",
    "python scripts/update_threat_rules.py --input assets/datasets/ --output config/\n",
    "\n",
    "# 4. Validate processed data\n",
    "python scripts/validate_datasets.py --datasets assets/datasets/processed/\n",
    "\n",
    "# 5. Generate data statistics\n",
    "python scripts/dataset_statistics.py --output reports/dataset_analysis.html\n",
    "\"\"\"\n",
    "\n",
    "# Save processing pipeline as shell script\n",
    "pipeline_script_path = project_root / \"scripts\" / \"process_datasets.sh\"\n",
    "pipeline_script_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with open(pipeline_script_path, 'w') as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    f.write(\"# SentinelGem Dataset Processing Pipeline\\n\")\n",
    "    f.write(\"# Author: Muzan Sano\\n\\n\")\n",
    "    f.write(processing_pipeline)\n",
    "\n",
    "# Make script executable\n",
    "import stat\n",
    "pipeline_script_path.chmod(pipeline_script_path.stat().st_mode | stat.S_IEXEC)\n",
    "\n",
    "print(f\"ðŸ’¾ Created processing pipeline: {pipeline_script_path}\")\n",
    "print(\"\\nðŸ”„ Processing Steps:\")\n",
    "print(\"1. Extract downloaded zip files\")\n",
    "print(\"2. Run preprocessing notebooks\")\n",
    "print(\"3. Update threat detection rules with real patterns\")\n",
    "print(\"4. Validate data quality and consistency\")\n",
    "print(\"5. Generate comprehensive dataset statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da292e49",
   "metadata": {},
   "source": [
    "## ðŸ“Š Dataset Summary & Next Actions\n",
    "\n",
    "Summary of identified datasets and immediate action items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive summary\n",
    "total_datasets = len(recommended_datasets) + len(audio_datasets) + len(image_datasets) + len(log_datasets)\n",
    "estimated_size = \"~3-5GB total (selective downloads)\"\n",
    "\n",
    "summary = {\n",
    "    \"total_datasets_identified\": total_datasets,\n",
    "    \"priority_downloads\": 6,\n",
    "    \"estimated_total_size\": estimated_size,\n",
    "    \"modalities_covered\": [\"text\", \"images\", \"audio\", \"logs\", \"network\"],\n",
    "    \"ready_for_download\": True\n",
    "}\n",
    "\n",
    "print(\"ðŸ“ˆ DATASET ACQUISITION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ðŸŽ¯ Total Datasets Identified: {summary['total_datasets_identified']}\")\n",
    "print(f\"ðŸ”¥ Priority Downloads: {summary['priority_downloads']}\")\n",
    "print(f\"ðŸ’¾ Estimated Size: {summary['estimated_total_size']}\")\n",
    "print(f\"ðŸŽ­ Modalities: {', '.join(summary['modalities_covered'])}\")\n",
    "print(f\"âœ… Ready for Download: {summary['ready_for_download']}\")\n",
    "\n",
    "print(\"\\nðŸš€ IMMEDIATE ACTION ITEMS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "action_items = [\n",
    "    \"1. ðŸ”‘ Set up Kaggle API credentials (kaggle.json)\",\n",
    "    \"2. ðŸ“¥ Download Priority 1 datasets (phishing, malware, spam)\",\n",
    "    \"3. ðŸ“ Extract datasets to assets/datasets/ structure\", \n",
    "    \"4. ðŸ”„ Run data preprocessing pipeline\",\n",
    "    \"5. ðŸ“Š Create data analysis notebooks (02_data_preprocessing.ipynb)\",\n",
    "    \"6. âš™ï¸ Update threat detection rules with real patterns\",\n",
    "    \"7. ðŸ§ª Validate SentinelGem performance on real data\",\n",
    "    \"8. ðŸ“ˆ Generate accuracy metrics and performance reports\"\n",
    "]\n",
    "\n",
    "for item in action_items:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nðŸŽ¯ SUCCESS METRICS:\")\n",
    "print(\"- Phishing detection accuracy >90%\")\n",
    "print(\"- Social engineering detection >85%\")\n",
    "print(\"- Malware detection accuracy >95%\")\n",
    "print(\"- False positive rate <5%\")\n",
    "print(\"- Real-time processing <2 seconds\")\n",
    "\n",
    "print(f\"\\nðŸ›¡ï¸ SentinelGem Dataset Acquisition Complete!\")\n",
    "print(f\"ðŸ“… Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"Ready to proceed with dataset downloads and integration. ðŸš€\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
